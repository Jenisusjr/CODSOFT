{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNi/NJrk1V+UWYOfxiJBiag"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Importing modules"],"metadata":{"id":"4q0UAcWfsm3X"}},{"cell_type":"code","source":["import torch\n","import torchvision.transforms as transforms\n","from torchvision.models import resnet50\n","from PIL import Image\n","import pickle\n","import numpy as np\n","from torch.nn.utils.rnn import pack_padded_sequence\n","import torch.nn as nn\n","import torch.optim as optim"],"metadata":{"id":"jveu1RZDsrnL","executionInfo":{"status":"ok","timestamp":1739255429234,"user_tz":-330,"elapsed":16798,"user":{"displayName":"Arvindh Babu V (Arvindh)","userId":"15735048412656218766"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Load pre-trained ResNet model for feature extraction"],"metadata":{"id":"jnsKNffNsuUZ"}},{"cell_type":"code","source":["class EncoderCNN(nn.Module):\n","    def __init__(self, embed_size):\n","        super(EncoderCNN, self).__init__()\n","        resnet = resnet50(pretrained=True)\n","        modules = list(resnet.children())[:-1]  # Remove the last fully connected layer\n","        self.resnet = nn.Sequential(*modules)\n","        self.linear = nn.Linear(resnet.fc.in_features, embed_size)\n","        self.bn = nn.BatchNorm1d(embed_size, momentum=0.01)\n","\n","    def forward(self, images):\n","        features = self.resnet(images)\n","        features = features.view(features.size(0), -1)\n","        features = self.bn(self.linear(features))\n","        return features"],"metadata":{"id":"Vwl24i7psy41","executionInfo":{"status":"ok","timestamp":1739255431931,"user_tz":-330,"elapsed":8,"user":{"displayName":"Arvindh Babu V (Arvindh)","userId":"15735048412656218766"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["LSTM-based Decoder for caption generation"],"metadata":{"id":"avdohnmgs_RB"}},{"cell_type":"code","source":["class DecoderRNN(nn.Module):\n","    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n","        super(DecoderRNN, self).__init__()\n","        self.embed = nn.Embedding(vocab_size, embed_size)\n","        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n","        self.linear = nn.Linear(hidden_size, vocab_size)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, features, captions, lengths):\n","        embeddings = self.embed(captions)\n","        embeddings = torch.cat((features.unsqueeze(1), embeddings), 1)\n","        packed = pack_padded_sequence(embeddings, lengths, batch_first=True, enforce_sorted=False)\n","        hiddens, _ = self.lstm(packed)\n","        outputs = self.linear(hiddens[0])\n","        return outputs\n"],"metadata":{"id":"mShVmps8s_9s","executionInfo":{"status":"ok","timestamp":1739255459260,"user_tz":-330,"elapsed":47,"user":{"displayName":"Arvindh Babu V (Arvindh)","userId":"15735048412656218766"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Load Image and Preprocess"],"metadata":{"id":"UnMvnF76tEWA"}},{"cell_type":"code","source":["def load_image(image_path, transform=None):\n","    image = Image.open(image_path).convert('RGB')\n","    if transform is not None:\n","        image = transform(image).unsqueeze(0)  # Add batch dimension\n","    return image"],"metadata":{"id":"oja8laa6tHYo","executionInfo":{"status":"ok","timestamp":1739255487764,"user_tz":-330,"elapsed":5,"user":{"displayName":"Arvindh Babu V (Arvindh)","userId":"15735048412656218766"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Transformations"],"metadata":{"id":"gH2Q7X_ItKS-"}},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","])"],"metadata":{"id":"60BtILnktMWe","executionInfo":{"status":"ok","timestamp":1739255505827,"user_tz":-330,"elapsed":37,"user":{"displayName":"Arvindh Babu V (Arvindh)","userId":"15735048412656218766"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Example Usage"],"metadata":{"id":"m7i3F6astO1F"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    embed_size = 256\n","    hidden_size = 512\n","    vocab_size = 5000  # Assume a vocabulary size\n","    num_layers = 1\n","\n","    encoder = EncoderCNN(embed_size)\n","    decoder = DecoderRNN(embed_size, hidden_size, vocab_size, num_layers)\n","\n","    # Load an example image\n","    image_path = \"/content/Cat.jpg.jpg\"  # Replace with your image path\n","    image = load_image(image_path, transform)\n","\n","    # Extract features\n","    encoder.eval()  # Set to evaluation mode\n","\n","# Extract features\n","    with torch.no_grad():\n","        features = encoder(image)\n","\n","    print(\"Extracted Features Shape:\", features.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JtDBXutK1ars","executionInfo":{"status":"ok","timestamp":1739257834548,"user_tz":-330,"elapsed":897,"user":{"displayName":"Arvindh Babu V (Arvindh)","userId":"15735048412656218766"}},"outputId":"91280413-b01e-4d8c-a885-37821bd2efcd"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Features Shape: torch.Size([1, 256])\n"]}]}]}